---
title: "Practice Lecture 13 MATH 390.4 Queens College"
author: "Professor Adam Kapelner"
date: "April 17, 2020"
---





# Wide and Long Dataframe Formats

We will demonstrate a new concept on the dataset from lab #8: storms.

```{r}
pacman::p_load(data.table, tidyverse, magrittr)
summary(storms)
head(storms)
```

Let's first create a few variables that are of interest:

```{r}
storms %<>% 
  mutate(wind_pct_avg = wind / mean(wind, na.rm = TRUE) * 100) %>%
  mutate(pressure_pct_avg = wind / mean(pressure, na.rm = TRUE) * 100) %>%
  mutate(ts_diameter_pct_avg = wind / mean(ts_diameter, na.rm = TRUE) * 100) %>%
  mutate(hu_diameter_pct_avg = wind / mean(hu_diameter, na.rm = TRUE) * 100)
ggplot(storms) + 
  aes(wind_pct_avg) + 
  geom_histogram()
```

Now let's take a look at these four variables we created for a storm we all remember and create a time period variable. I'll also instantiate a data.table object for later:

```{r}
sandy_wide_tbl = storms %>% 
  filter(name == "Sandy") %>%
  select(wind_pct_avg, pressure_pct_avg, ts_diameter_pct_avg, hu_diameter_pct_avg) %>% #we only care about our variables
  mutate(period = 1 : n()) %>%
  select(period, everything()) #reorder
sandy_wide_dt = data.table(sandy_wide_tbl)
sandy_wide_dt
```

This is called a "repeated measures" dataset or a "time series" and it is one of the most common data frame types. Unfortunately, we didn't have enough classtime to do a unit on time series. It really deserves its own class!

Regardless, it would be nice to be able to visualize It would be nice to look at the four variables we just created by time period. We can do this below:

```{r}
ggplot(sandy_wide_tbl) + 
  aes(x = period) + 
  geom_line(aes(y = wind_pct_avg), col = "red") + 
  geom_line(aes(y = pressure_pct_avg), col = "green") + 
  geom_line(aes(y = ts_diameter_pct_avg), col = "blue") + 
  geom_line(aes(y = hu_diameter_pct_avg), col = "grey") +
  ylab("% over average")
```

Notice how that was a lot of lines of code which aren't so maintainable and we don't have a legend. Legends are built automatically in `ggplot2` when we set color to a variable. This means we somehow have to let the four variables we care about be there own categorical variable.

First note that the dataframe we have is in what's called "wide format" or "unstacked" meaning each row is an observation and the columns are its features. This is exactly the format of dataframe that we've been studying in this class. This is the format we humans prefer to read and it is the format for many important analyses and the format for modeling.

However, to get what we want above involves a "reshaping" our dataframe into another canonical form, one that is easier for machines to read, a format called "long format" or "narrow" or "stacked" which looks like this:

| Period      | Value       | variable     |
| ----------- | ----------- | -------------|
| 1           | 56.08       | wind_pct_avg |
| 2           | 65.43       | wind_pct_avg |
etc.

Sometimes this format is required for situations, so we should get used to "pivoting" between the two formats. 

We first go from wide to long. To do so, we identify the "id variables" which get their own row per category and the measurement variables which get their own entire subdataframe.

```{r}
sandy_long_tbl = pivot_longer(
  sandy_wide_tbl, 
  cols = -period, #measurement variables: all column except period and period is then the ID variable
  names_to = "metric", #default is "name"
  values_to = "val" #default is "value"
)
sandy_long_dt = melt(
  sandy_wide_dt,
  id.vars = "period",
  measure.vars = c("wind_pct_avg", "pressure_pct_avg", "ts_diameter_pct_avg", "hu_diameter_pct_avg"),
  variable.name = "metric",
  value.name = "val"
)
sandy_long_tbl
sandy_long_dt
```

Same output but note the difference in sorting: `tidyverse` sorts on the id variables first and `data.table` sorts on the measurements i.e. cbinding the subdataframes.

Now that it's in long format, the visualization code becomes very simple:

```{r}
ggplot(sandy_long_dt) +
  geom_line(aes(x = period, y = val, color = metric)) +
  ylab("% over average")
```

Now we go from long to wide:

```{r}
sandy_wide_tbl2 = pivot_wider(
  sandy_long_tbl,
  id_cols = period, 
  names_from = metric,
  values_from = val
)
sandy_wide_dt2 = dcast(
  sandy_long_dt,
  period ~ metric, #lhs is id and rhs is measurement variables
  value.var = "val" #the function can guess "val" has to be the cell values so it's not needed
)
sandy_wide_tbl2
sandy_wide_dt2
```

Who's faster?

```{r}
pacman::p_load(microbenchmark)
microbenchmark(
  wide_to_long_tidy = pivot_longer(
    sandy_wide_tbl, 
    cols = -period,
    names_to = "metric",
    values_to = "val"
  ),
  wide_to_long_dt = melt(
    sandy_wide_dt,
    id.vars = "period",
    measure.vars = c("wind_pct_avg", "pressure_pct_avg", "ts_diameter_pct_avg", "hu_diameter_pct_avg"),
    variable.name = "metric",
    value.name = "val"
  ),
  long_to_wide_tidy = pivot_wider(
    sandy_long_tbl,
    id_cols = period, 
    names_from = metric,
    values_from = val
  ),
  long_to_wide_dt = dcast(
    sandy_long_dt,
    period ~ metric,
    value.var = "val"
  ),
  times = 50
)
```

Looks like ``data.table::melt`` is 60x faster than tidyverse's pivot and ``data.tabe::dcast` is 2x faster than tidyverse's pivot.

# Joins

Another one of the core data munging skills is joining data frames together. In the real world, databases consist of multiple dataframes called "tables" and design matrices are built by gathering data from among many tables. To illustrate this, we load two datasets from the package `nycflights13`, one dataset about weather and one about airports:

```{r}
pacman::p_load(nycflights13, data.table, tidyverse, magrittr)
data(weather)
summary(weather)
data(airports)
summary(airports)
```

Note how the weather and airports datasets contain a common feature: name of airport. It is called `FAA` in airports and `origin` in weather.

First we rename the column in weather to match the column in airports:

```{r}
weather %<>% 
  rename(faa = origin)
```

We also pare down the datasets so we can see the joins more clearly:

```{r}
airports %<>% 
  select(faa, lat, lon)
weather %<>% 
  select(faa, time_hour, temp, humid, wind_speed, pressure, wind_gust)
head(airports)
head(weather)
airports_dt = data.table(airports)
weather_dt = data.table(weather)
```

Some features just aren't measured that often e.g. `wind_gust`.

Let's do some joins. First "left". This is likely the most common because it's usually how we conceptualize what we're doing in our heads.

```{r}
airports_and_weather = left_join(airports, weather, by = "faa")
airports_and_weather %>% sample_n(500)
airports_and_weather_dt = merge(airports_dt, weather_dt, by = "faa", all.x = TRUE)
airports_and_weather_dt = merge(airports_dt, weather_dt, all.x = TRUE) #note this works too since it knows faa is the only column in common but not recommended since specifying "by" is more clear
airports_and_weather_dt[sample(1 : .N, 500)]
```

Now "right"

```{r}
airports_and_weather = right_join(airports, weather, by = "faa")
airports_and_weather %>% sample_n(500)
airports_and_weather_dt = merge(airports_dt, weather_dt, by = "faa", all.y = TRUE)
airports_and_weather_dt = merge(airports_dt, weather_dt, all.y = TRUE)
airports_and_weather_dt[sample(1 : .N, 500)]
```


```{r}
airports_and_weather = inner_join(airports, weather, by = "faa")
airports_and_weather %>% sample_n(500)
airports_and_weather_dt = merge(airports_dt, weather_dt, by = "faa")
airports_and_weather_dt = merge(airports_dt, weather_dt)
airports_and_weather_dt[sample(1 : .N, 500)]
```

And full, keeping all the rows. We use a subset to show how this works:

```{r}
airports_without_EWR = airports %>%
  filter(faa != "EWR")
airports_without_EWR_dt = data.table(airports_without_EWR)
airports_without_EWR_and_weather = full_join(airports_without_EWR, weather, by = "faa")
airports_without_EWR_and_weather %>% sample_n(500)
airports_without_EWR_and_weather_dt = merge(airports_without_EWR_dt, weather_dt, by = "faa", all = TRUE)
airports_without_EWR_and_weather_dt = merge(airports_without_EWR_dt, weather_dt, all = TRUE)
airports_without_EWR_and_weather_dt[sample(.N, 500)]
```

There is also `semi_join` and `anti_join` that do the opposite of joining. In my experience, these use cases are limited.
